{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b82ba56",
   "metadata": {},
   "source": [
    "# Script for starting the phasing analysis in Yale - Penn\n",
    "\n",
    "Author: Jose Jaime Martinez-Magana\n",
    "\n",
    "Day: 25 February 2023\n",
    "\n",
    "This script was developed to start the phasing analysis using shapeit in Yale Penn 2 cohort, for the empirical testing of Tractor - Mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this analysis we used shapeit2, for a detail documentation follow this link:\n",
    "# https://mathgen.stats.ox.ac.uk/genetics_software/shapeit/shapeit.html\n",
    "\n",
    "# if your cluster uses slurm as job handler follow the next command for requesting resources\n",
    "# request resources in slurm based HPC\n",
    "srun --pty --mem=32G -p interactive bash\n",
    "\n",
    "# load miniconda\n",
    "module load miniconda\n",
    "# activate tractor-mix environmnet\n",
    "conda activate tractor_mix\n",
    "\n",
    "# move to your analysis directory\n",
    "cd palmer_scratch/genomics/yalepenn/tractor_mix/\n",
    "\n",
    "# move to the databases directory\n",
    "cd databases/\n",
    "# create a directory to sctore the genotype data, named genotype/\n",
    "mkdir genotype/\n",
    "# WARNING remember to run mkdir, only once !!!!\n",
    "# if you directories has been created just move to it with cd (Linux)\n",
    "cd genotype\n",
    "\n",
    "# create a directory to store the original data, filtered data and phased data, named original_data/, filtered/ and phased/\n",
    "mkdir original_data/ filtered/ phased/\n",
    "# WARNING remember to run mkdir, only once !!!!\n",
    "# if you directories has been created just move to it with cd (Linux)\n",
    "cd original_data/\n",
    "\n",
    "# make a copy of yale penn, we have previous analyzed Yale Penn and is stored in the following path\n",
    "# /vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/nic_dep/genomic_data/vcfs/annot_rsids/yp2/\n",
    "cp /vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/nic_dep/genomic_data/vcfs/annot_rsids/yp2/GWGO_GWCIDR.1kg_phase3_v5.chr* .\n",
    "# WARNING remember to run cp only once, if run again the previous line, will overwritte your data\n",
    "# this could tak a while, depending on your sample size\n",
    "\n",
    "\n",
    "# inside scripts/ in our environment create the following directories\n",
    "mkdir environment  local_anc  phasing  pheno\n",
    "# WARNING remember to run mkdir, only once !!!!\n",
    "# if you directories has been created just move to it with cd (Linux)\n",
    "cd phasing\n",
    "# the scripts from this notebook should be found in the phasing directory\n",
    "# this part of the script was used for developing the next scripts and adjusting the environment for the outputs\n",
    "# and input structure of the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to filter the vcf to include only SNPs with imputation score > 0.80\n",
    "# for this we are going to use bcftools\n",
    "# the following script is going to be added to the bash script filter_samples.sh\n",
    "# this script uses a sample list in our specific analysis is a list of the sampleIDs with the form FID_IID, no header\n",
    "# we have created this list and could be found in the following path\n",
    "# /vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/sample_lists/tractor_mix_samples.list.forvcfs\n",
    "# start script\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=yale_penn_generate_vcf_subset\n",
    "#SBATCH --out=\"slurm-%j.out\"\n",
    "#SBATCH --time=20:00:00\n",
    "#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=90G\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --partition=bigmem\n",
    "####################################################################################\n",
    "# script to stratify the Yale Penn 2 cohort based on our previous selection of samples\n",
    "# for this analysis we used a thresold of higher than 50% of African Ancestry\n",
    "# day: 26 February 2023\n",
    "# analyzer: Jose Jaime Martinez-Magana - jjm262\n",
    "# cluster: Grace - HPC Yale\n",
    "####################################################################################\n",
    "# This script uses the Yale Penn cohort imputed vcfs annotated with rsIDs\n",
    "####################################################################################\n",
    "# load conda \n",
    "module load miniconda\n",
    "# activate tractor_mix environment\n",
    "conda activate tractor_mix\n",
    "# set parameters\n",
    "# input paths for Yale Penn vcfs annotated with rsIDs\n",
    "vcfip='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/original_data'\n",
    "# sample filter\n",
    "sm_f='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/sample_lists/tractor_mix_samples.list.forvcfs'\n",
    "# set output path\n",
    "vcfup='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/filtered'\n",
    "# set path to bcftools from our environment\n",
    "bcftools='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/scripts/environment/extdata/bcftools/bcftools/bcftools'\n",
    "# running script\n",
    "for chr in {1..22}\n",
    "do\n",
    "$bcftools view -i 'R2>=0.8' ${vcfip}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.vcf.gz \\\n",
    "--output-file ${vcfup}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.vcf.gz \\\n",
    "--samples-file ${sm_f} \\\n",
    "--output-type z \\\n",
    "--threads $SLURM_CPUS_PER_TASK\n",
    "done\n",
    "# end of script\n",
    "# run the previous script with the next command, for this your server should have a slurm handler\n",
    "# if not run your script with your handler\n",
    "sbatch filter_samples.sh\n",
    "# notes: slurm-16051489.out, error because header in samples-file, slurm-16051613.out, running succesfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a script to remove duplicated from the vcf files, named nodup_vcf.sh, if needed it\n",
    "# start script\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=yale_penn_remove_dup_vcf\n",
    "#SBATCH --out=\"slurm-%j.out\"\n",
    "#SBATCH --time=24:00:00\n",
    "#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=90G\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --partition=bigmem\n",
    "####################################################################################\n",
    "# script to index the filtered samples Yale Penn 2 cohort based on our previous selection of samples\n",
    "# for this analysis we used a thresold of higher than 50% of African Ancestry\n",
    "# day: 26 February 2023\n",
    "# analyzer: Jose Jaime Martinez-Magana - jjm262\n",
    "# cluster: Grace - HPC Yale\n",
    "####################################################################################\n",
    "# This script uses the Yale Penn cohort imputed vcfs annotated with rsIDs\n",
    "####################################################################################\n",
    "# load conda \n",
    "module load miniconda\n",
    "# activate tractor_mix environment\n",
    "conda activate tractor_mix\n",
    "# set parameters\n",
    "# input paths for filtered Yale Penn 2 files\n",
    "vcfip='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/filtered'\n",
    "# set path to bcftools from our environment\n",
    "bcftools='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/scripts/environment/extdata/bcftools/bcftools/bcftools'\n",
    "# running script\n",
    "# move to input directory\n",
    "for chr in {1..22}\n",
    "do\n",
    "$bcftools norm -d all ${vcfip}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.vcf.gz \\\n",
    "--output ${vcfip}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.nodup.vcf.gz \\\n",
    "--output-type z \\\n",
    "--threads $SLURM_CPUS_PER_TASK\n",
    "done\n",
    "# end of script\n",
    "# we highly recommend removing duplicates in your data, but if you believe that your data does not requiered this step,\n",
    "# you could not perform it, in this notebook, we will continue with the remove duplicate for further analysis\n",
    "# run the previous script with the next command, for this your server should have a slurm handler\n",
    "# if not run your script with your handler\n",
    "sbatch nodup_vcf.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46300982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also adding a script to index the vcf files, named index_sample_vcf.sh, if needed it\n",
    "# start script\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=yale_penn_index_vcfs\n",
    "#SBATCH --out=\"slurm-%j.out\"\n",
    "#SBATCH --time=36:00:00\n",
    "#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=2\n",
    "#SBATCH --mem-per-cpu=32G\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --partition=week\n",
    "####################################################################################\n",
    "# script to index the filtered samples Yale Penn 2 cohort based on our previous selection of samples\n",
    "# for this analysis we used a thresold of higher than 50% of African Ancestry\n",
    "# day: 26 February 2023\n",
    "# analyzer: Jose Jaime Martinez-Magana - jjm262\n",
    "# cluster: Grace - HPC Yale\n",
    "####################################################################################\n",
    "# This script uses the Yale Penn cohort imputed vcfs annotated with rsIDs\n",
    "####################################################################################\n",
    "# load conda \n",
    "module load miniconda\n",
    "# activate tractor_mix environment\n",
    "conda activate tractor_mix\n",
    "# set parameters\n",
    "# input paths for filtered Yale Penn 2 files\n",
    "vcfip='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/filtered'\n",
    "# set path to bcftools from our environment\n",
    "bcftools='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/scripts/environment/extdata/bcftools/bcftools/bcftools'\n",
    "# running script\n",
    "# move to input directory\n",
    "cd ${vcfip}\n",
    "for chr in {1..22}\n",
    "do\n",
    "$bcftools index GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.nodup.vcf.gz\n",
    "done\n",
    "# end of script\n",
    "# run the previous script with the next command, for this your server should have a slurm handler\n",
    "# if not run your script with your handler\n",
    "sbatch index_sample_vcf.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80482af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a script for checking the input files with the reference for shapeit2, named check_shapeit2.sh\n",
    "# start script\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=yale_penn_check_vcf_file\n",
    "#SBATCH --out=\"slurm-%j.out\"\n",
    "#SBATCH --time=22:00:00\n",
    "#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=4\n",
    "#SBATCH --mem-per-cpu=250G\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --partition=bigmem\n",
    "####################################################################################\n",
    "# script to check phased files Yale Penn 2 cohort for tractor mix, before local ancestry\n",
    "# day: 26 February 2023\n",
    "# analyzer: Jose Jaime Martinez-Magana - jjm262\n",
    "# cluster: Grace - HPC Yale\n",
    "####################################################################################\n",
    "# This script uses the Yale Penn cohort filtered information\n",
    "####################################################################################\n",
    "# load conda \n",
    "module load miniconda\n",
    "# activate tractor_mix environment\n",
    "conda activate tractor_mix\n",
    "# set input \n",
    "# set path for input vcf files\n",
    "vcfip='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/filtered'\n",
    "# set path for phased output vcf files\n",
    "vcfop='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/phased'\n",
    "# set path input for haplotypes of references\n",
    "hap_ref='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/haplotypes/1000GP_Phase3'\n",
    "# set path input for genetic maps\n",
    "map_ref='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/genetic_maps'\n",
    "# phasing data with shapeit2\n",
    "for chr in {1.22}\n",
    "do\n",
    "shapeit -check --input-vcf ${vcfip}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.nodup.vcf.gz \\\n",
    "--input-map ${map_ref}/genetic_map_GRCh37_chr${chr}.txt \\\n",
    "--input-ref ${hap_ref}/1000GP_Phase3_chr${chr}.hap.gz ${hap_ref}/1000GP_Phase3_chr${chr}.legend.gz ${hap_ref}/1000GP_Phase3.sample \\\n",
    "--thread $SLURM_CPUS_PER_TASK \\\n",
    "--output-log ${vcfop}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.test_aligment_check\n",
    "done\n",
    "# end script\n",
    "# this script will generate a list of positions to be excluded from the vcf file\n",
    "# run the previous script with the next command, for this your server should have a slurm handler\n",
    "# if not run your script with your handler\n",
    "sbatch check_shapeit2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe60b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for phasing we will used only the samples from 1000G of AFR and EUR ancestry, for this reason \n",
    "# we need to create a file, named ances_groups.list\n",
    "# that will be the input to shapeit2 for only considering those ancestry groups in the phasing\n",
    "# to generate this script we follow the next script in any bash\n",
    "sample_path='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/haplotypes/1000GP_Phase3'\n",
    "sample_list='1000GP_Phase3.sample'\n",
    "# we have decided to use only individuals from the following populations\n",
    "# FIN Finnish Finnish in Finland\n",
    "# IBS Iberian Iberian populations in Spain\n",
    "# GBR British British in England and Scotland\n",
    "# TSI Toscani Toscani in Italy\n",
    "# YRI Yoruba Yoruba in Ibadan, Nigeria\n",
    "# GWD Gambian Mandinka Gambian in Western Division, The Gambia - Mandinka\n",
    "# MSL Mende Mende in Sierra Leone\n",
    "# ESN Esan Esan in Nigeria\n",
    "# LWK Luhya Luhya in Webuye, Kenya\n",
    "cat ${sample_path}/${sample_list} | egrep 'FIN|\\IBS|\\GBR|\\TSI|\\YRI|\\GWD|\\MSL|\\ESN|\\LWK' | cut -f 2 -d\" \" | sort | uniq > ${sample_path}/ances_groups.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1040038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a script for phasing with shapeit2, named phase_shapeit2.sh\n",
    "# start script\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=yale_penn_phasing_shapeit2\n",
    "#SBATCH --out=\"slurm-%j.out\"\n",
    "#SBATCH --time=22:00:00\n",
    "#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=32G\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --partition=bigmem\n",
    "####################################################################################\n",
    "# script to phased Yale Penn 2 cohort for tractor mix, before local ancestry\n",
    "# day: 26 February 2023\n",
    "# analyzer: Jose Jaime Martinez-Magana - jjm262\n",
    "# cluster: Grace - HPC Yale\n",
    "####################################################################################\n",
    "# This script uses the Yale Penn cohort filtered information\n",
    "####################################################################################\n",
    "# load conda \n",
    "module load miniconda\n",
    "# activate tractor_mix environment\n",
    "conda activate tractor_mix\n",
    "# set input \n",
    "# set path for input vcf files\n",
    "vcfip='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/filtered'\n",
    "# set path for phased output vcf files\n",
    "vcfop='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/genotype/phased'\n",
    "# set path input for haplotypes of references\n",
    "hap_ref='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/haplotypes/1000GP_Phase3'\n",
    "# set path input for genetic maps\n",
    "map_ref='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/haplotypes/1000GP_Phase3'\n",
    "# set group list, to only include those in the filtering\n",
    "group_list='/vast/palmer/scratch/montalvo-ortiz/jjm262/genomics/yalepenn/tractor_mix/databases/shapeit/haplotypes/1000GP_Phase3/ances_groups.list'\n",
    "# phasing data with shapeit2\n",
    "for chr in {1..22}\n",
    "do\n",
    "shapeit --input-vcf ${vcfip}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.nodup.vcf.gz \\\n",
    "--input-map ${map_ref}/genetic_map_chr${chr}_combined_b37.txt \\\n",
    "--input-ref ${hap_ref}/1000GP_Phase3_chr${chr}.hap.gz ${hap_ref}/1000GP_Phase3_chr${chr}.legend.gz ${hap_ref}/1000GP_Phase3.sample \\\n",
    "--include-grp ${group_list} \\\n",
    "--exclude-snp ${vcfop}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.test_aligment_check.strand.exclude \\\n",
    "--thread $SLURM_CPUS_PER_TASK \\\n",
    "-O ${vcfop}/GWGO_GWCIDR.1kg_phase3_v5.chr$chr.dose.rsids.filtered.nodup.phased.vcf.gz\n",
    "done\n",
    "# end script\n",
    "# run the previous script with the next command, for this your server should have a slurm handler\n",
    "# if not run your script with your handler\n",
    "sbatch phase_shapeit2.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
